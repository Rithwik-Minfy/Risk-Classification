{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b44211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import kagglehub\n",
    "import mlflow\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "    \n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, DataSummaryPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a29dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save dir\n",
    "import os\n",
    "SAVEDIR = os.getenv('ARTIFACT_DIR', '.') + '/saved_models'\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_excel(\n",
    "        \"Bank_Personal_Loan_Modelling.xlsx\",\n",
    "        sheet_name='Data'\n",
    "    )\n",
    "    # DROP via keyword axis=\n",
    "    return df.drop(['ID', 'ZIP Code'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43975a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, DataSummaryPreset\n",
    "\n",
    "def log_evidently_report(reference_data, current_data, dataset_name=\"train_vs_test\"):\n",
    "    \n",
    "    #  Align columns: use only the intersection to avoid partial-column errors\n",
    "    common_cols = set(reference_data.columns).intersection(current_data.columns)\n",
    "    if not common_cols:\n",
    "        print(f\"⚠️ No common columns between reference and {dataset_name}; skipping Evidently report.\")\n",
    "        return\n",
    "    ref = reference_data[sorted(common_cols)]\n",
    "    cur = current_data[sorted(common_cols)]\n",
    "\n",
    "    #  Run the Evidently report (drift + summary)\n",
    "    report = Report(metrics=[DataDriftPreset(), DataSummaryPreset()])\n",
    "    result = report.run(reference_data=ref, current_data=cur)\n",
    "\n",
    "    #  Ensure local save directory exists\n",
    "    save_dir = Path.cwd() / \"evidently_reports\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #  Save HTML and JSON\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    html_path = save_dir / f\"evidently_{dataset_name}_{ts}.html\"\n",
    "    json_path = save_dir / f\"evidently_{dataset_name}_{ts}.json\"\n",
    "    result.save_html(str(html_path))\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(result.json())\n",
    "\n",
    "    #  Log artifacts to MLflow\n",
    "    mlflow.log_artifact(str(html_path), artifact_path=\"evidently\")\n",
    "    mlflow.log_artifact(str(json_path), artifact_path=\"evidently\")\n",
    "    print(f\"📄 Logged HTML: {html_path.name}\")\n",
    "    print(f\"🗄️  Logged JSON: {json_path.name}\")\n",
    "\n",
    "    #  Load JSON and extract metrics list\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        report_json = json.load(fp)\n",
    "    metrics_list = report_json.get(\"metrics\", [])\n",
    "\n",
    "    #  Overall drifted columns metrics\n",
    "    drift_entry = next((m for m in metrics_list if m.get(\"metric_id\", \"\").startswith(\"DriftedColumnsCount\")), None)\n",
    "    if drift_entry:\n",
    "        count = drift_entry[\"value\"][\"count\"]\n",
    "        share = drift_entry[\"value\"][\"share\"]\n",
    "        mlflow.log_metric(\"drifted_columns_count\", float(count))\n",
    "        mlflow.log_metric(\"drifted_columns_share\", float(share))\n",
    "        print(f\"🔢 drifted_columns_count = {count}\")\n",
    "        print(f\"🔢 drifted_columns_share = {share}\")\n",
    "    else:\n",
    "        print(\"⚠️ No DriftedColumnsCount entry found.\")\n",
    "\n",
    "    #  Row and column counts\n",
    "    rowcount = next((m[\"value\"] for m in metrics_list if m.get(\"metric_id\") == \"RowCount()\"), None)\n",
    "    colcount = next((m[\"value\"] for m in metrics_list if m.get(\"metric_id\") == \"ColumnCount()\"), None)\n",
    "    if rowcount is not None:\n",
    "        mlflow.log_metric(\"dataset_row_count\", float(rowcount))\n",
    "        print(f\"🔢 dataset_row_count = {rowcount}\")\n",
    "    if colcount is not None:\n",
    "        mlflow.log_metric(\"dataset_column_count\", float(colcount))\n",
    "        print(f\"🔢 dataset_column_count = {colcount}\")\n",
    "\n",
    "    #  Per-feature value drift metrics\n",
    "    for m in metrics_list:\n",
    "        mid = m.get(\"metric_id\", \"\")\n",
    "        if mid.startswith(\"ValueDrift(column=\"):\n",
    "            # extract column name\n",
    "            col = mid.split(\"=\")[1].rstrip(\")\")\n",
    "            val = m.get(\"value\")\n",
    "            if isinstance(val, (int, float)):\n",
    "                mlflow.log_metric(f\"drift_{col}\", float(val))\n",
    "                print(f\"🔢 drift_{col} = {val}\")\n",
    "    \n",
    "    print(\"✅ All requested drift & dataset metrics logged to MLflow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b159f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"Risk Classification Evidently\"\n",
    "\n",
    "def main():\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # ─── 1️⃣ Ensure the MLflow experiment exists and is active ───\n",
    "    exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if exp is None:\n",
    "        exp_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"✅ Created new experiment '{EXPERIMENT_NAME}' (ID={exp_id})\")\n",
    "    elif exp.lifecycle_stage == \"deleted\":\n",
    "        client.restore_experiment(exp.experiment_id)\n",
    "        print(f\"🔄 Restored deleted experiment '{EXPERIMENT_NAME}' (ID={exp.experiment_id})\")\n",
    "    else:\n",
    "        print(f\"ℹ️ Using existing experiment '{EXPERIMENT_NAME}' (ID={exp.experiment_id})\")\n",
    "\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    # ─── 2️⃣ Start your MLflow run ───\n",
    "    with mlflow.start_run(run_name=\"Preprocessing and Tuning\"):\n",
    "        # Load and split\n",
    "        df = load_data()\n",
    "        Xtr, Xv, Xt, ytr, yv, yt = split_data(df)\n",
    "\n",
    "        # Keep raw for Evidently\n",
    "        df_train = Xtr.copy()\n",
    "        df_test  = Xt.copy()\n",
    "\n",
    "        # Load or simulate new batch\n",
    "        csv_path = \"New_Customer_Bank_Personal_Loan.csv\"\n",
    "        df_new = pd.read_csv(csv_path)\n",
    "        if \"Defaulter\" in df_new.columns:\n",
    "            df_new = df_new.drop(columns=[\"Defaulter\"])\n",
    "\n",
    "        # Log Evidently reports\n",
    "        log_evidently_report(df_train, df_test,      dataset_name=\"train_vs_test\")\n",
    "        log_evidently_report(df_train, df_new,        dataset_name=\"train_vs_new_batch\")\n",
    "        log_evidently_report(df_test,  df_new,        dataset_name=\"test_vs_new_batch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0266f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Using existing experiment 'Risk Classification Evidently' (ID=458900522193773038)\n",
      "📄 Logged HTML: evidently_train_vs_test_2025-07-03_10-30-41.html\n",
      "🗄️  Logged JSON: evidently_train_vs_test_2025-07-03_10-30-41.json\n",
      "🔢 drifted_columns_count = 0.0\n",
      "🔢 drifted_columns_share = 0.0\n",
      "🔢 dataset_row_count = 1500.0\n",
      "🔢 dataset_column_count = 11.0\n",
      "🔢 drift_Age = 0.028061626698313084\n",
      "🔢 drift_CCAvg = 0.03250447331201192\n",
      "🔢 drift_Experience = 0.026506967833842664\n",
      "🔢 drift_Income = 0.029321736822988533\n",
      "🔢 drift_Mortgage = 0.02517476499730154\n",
      "🔢 drift_CD Account = 0.00032384174356389915\n",
      "🔢 drift_CreditCard = 0.01668874408751289\n",
      "🔢 drift_Education = 0.012499112211892531\n",
      "🔢 drift_Family = 0.018132241949840956\n",
      "🔢 drift_Online = 0.0005154147823947248\n",
      "🔢 drift_Securities Account = 0.003982768135332864\n",
      "✅ All requested drift & dataset metrics logged to MLflow.\n",
      "📄 Logged HTML: evidently_train_vs_new_batch_2025-07-03_10-30-44.html\n",
      "🗄️  Logged JSON: evidently_train_vs_new_batch_2025-07-03_10-30-44.json\n",
      "🔢 drifted_columns_count = 10.0\n",
      "🔢 drifted_columns_share = 0.9090909090909091\n",
      "🔢 dataset_row_count = 15.0\n",
      "🔢 dataset_column_count = 11.0\n",
      "🔢 drift_Age = 0.6784517260788467\n",
      "🔢 drift_CCAvg = 0.20186945281016913\n",
      "🔢 drift_Experience = 0.6592922581420443\n",
      "🔢 drift_Income = 0.22937836837607442\n",
      "🔢 drift_CD Account = 0.14356849266624733\n",
      "🔢 drift_CreditCard = 0.21021766954612256\n",
      "🔢 drift_Education = 0.12319208872316273\n",
      "🔢 drift_Family = 0.16287618565307088\n",
      "🔢 drift_Mortgage = 0.40339915956512784\n",
      "🔢 drift_Online = 0.09412213922767908\n",
      "🔢 drift_Securities Account = 0.19281117723521934\n",
      "✅ All requested drift & dataset metrics logged to MLflow.\n",
      "📄 Logged HTML: evidently_test_vs_new_batch_2025-07-03_10-30-47.html\n",
      "🗄️  Logged JSON: evidently_test_vs_new_batch_2025-07-03_10-30-47.json\n",
      "🔢 drifted_columns_count = 10.0\n",
      "🔢 drifted_columns_share = 0.9090909090909091\n",
      "🔢 dataset_row_count = 15.0\n",
      "🔢 dataset_column_count = 11.0\n",
      "🔢 drift_Age = 0.706391439030911\n",
      "🔢 drift_CCAvg = 0.19097116227726915\n",
      "🔢 drift_Experience = 0.6840579730575301\n",
      "🔢 drift_Income = 0.2499021879229749\n",
      "🔢 drift_CD Account = 0.1432982600797981\n",
      "🔢 drift_CreditCard = 0.22610293852562893\n",
      "🔢 drift_Education = 0.1318583372899813\n",
      "🔢 drift_Family = 0.15836984465054582\n",
      "🔢 drift_Mortgage = 0.39824121018964054\n",
      "🔢 drift_Online = 0.09463520038696382\n",
      "🔢 drift_Securities Account = 0.19614023756878277\n",
      "✅ All requested drift & dataset metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42421ba9-fc03-4540-a887-24bb7d28dddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
